{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "def load_data(batch_size = 1000):\n",
    "    # load data CIFAR10\n",
    "\n",
    "    # transform to tensor and normalize to [-1,1]\n",
    "    transform = transforms.Compose(\n",
    "        [\n",
    "    #         transforms.Resize(256),\n",
    "            transforms.ToTensor(),\n",
    "         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                            download=True, transform=transform)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                              shuffle=True, num_workers=0)\n",
    "\n",
    "    testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                           download=True, transform=transform)\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                             shuffle=False, num_workers=0)\n",
    "    return trainset, trainloader, testset, testloader\n",
    "\n",
    "# define model\n",
    "class LogisticRegression(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = torch.nn.Linear(3072, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y_pred = F.sigmoid(self.linear(x))\n",
    "        return y_pred\n",
    "    \n",
    "    \n",
    "def train_vali_split_loader(trainset, batch_size = 1024, num_workers=0):\n",
    "    trainset_, valset_ = torch.utils.data.random_split(trainset, \n",
    "                              [int(0.8*len(trainset)), \n",
    "                               int(0.2*len(trainset))])\n",
    "    \n",
    "    trainloader_ = torch.utils.data.DataLoader(trainset_, \n",
    "                                              batch_size=batch_size,\n",
    "                                              shuffle=True, \n",
    "                                              num_workers=0)\n",
    "    \n",
    "    valiloader_ = torch.utils.data.DataLoader(valset_, \n",
    "                                              batch_size=batch_size,\n",
    "                                              shuffle=True, \n",
    "                                              num_workers=0)\n",
    "    return (trainloader_, valiloader_)\n",
    "\n",
    "\n",
    "def test_model(model, testloader):\n",
    "        predicted_correct_num = 0\n",
    "        total_test = 0\n",
    "        # run on vali set to get accuracy\n",
    "        for i, data in enumerate(testloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "    #         inputs, labels = data\n",
    "            inputs, labels = data[0].view(batch_size, -1), data[1]\n",
    "\n",
    "            predicted_test = torch.max(model(inputs), 1)\n",
    "\n",
    "            total_test += labels.size(0)\n",
    "            predicted_correct_num += sum(predicted_test.indices == labels)\n",
    "            print(\"Test {0} th batch, {1} correct, tested {2}, batch size {3}\".format(i, \n",
    "                                                                          predicted_correct_num,\n",
    "                                                                          batch_size*(i+1), batch_size))\n",
    "\n",
    "        accu_test = predicted_correct_num.item() / total_test\n",
    "        return accu_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 µs, sys: 0 ns, total: 4 µs\n",
      "Wall time: 7.87 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def train_and_vali(trainset, model, optimizer, title, testloader,\n",
    "                   epochs=70, batch_print_num=20, \n",
    "                   batch_size=32):\n",
    "    # train the last layer of the model, using batch size 1024, 70 epochs \n",
    "    # batch_size = 32\n",
    "    accu_train_list = []\n",
    "    accu_vali_list = []\n",
    "    for epoch in range(epochs):    # loop over the dataset multiple times\n",
    "        # splite train into train and vali\n",
    "        trainloader_, valiloader_ = train_vali_split_loader(trainset, batch_size = batch_size)\n",
    "\n",
    "        running_loss = 0.0\n",
    "        predicted_correct_num_train = 0\n",
    "        total_train = 0\n",
    "        for i, data in enumerate(trainloader_, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "#             inputs, labels = data[0].view(batch_size, -1), data[1] # -> linear input\n",
    "            inputs, labels = data\n",
    "#             print(inputs.size())\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            batch_print_num = batch_print_num\n",
    "            running_loss += loss.item()\n",
    "            if i % batch_print_num == batch_print_num-1:      # print every 5 mini-batches\n",
    "                print('[%d, %5d] loss: %0.3f'%(epoch+1,batch_size*(i+1), \n",
    "                      running_loss / batch_print_num))\n",
    "                running_loss = 0.0\n",
    "\n",
    "            # training accu\n",
    "            predicted_train = torch.max(outputs, 1)\n",
    "            total_train += labels.size(0)\n",
    "            predicted_correct_num_train += sum(predicted_train.indices == labels)\n",
    "\n",
    "        accu_train = predicted_correct_num_train.item() / total_train\n",
    "        accu_train_list.append(accu_train)\n",
    "\n",
    "        predicted_correct_num = 0\n",
    "        total_vali = 0\n",
    "        # run on vali set to get accuracy\n",
    "        for i, data in enumerate(valiloader_, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "#             inputs, labels = data[0].view(batch_size, -1), data[1] # -> linear input\n",
    "        \n",
    "#             print(inputs.size())\n",
    "\n",
    "            predicted_vali = torch.max(model(inputs), 1)\n",
    "\n",
    "            total_vali += labels.size(0)\n",
    "            predicted_correct_num += sum(predicted_vali.indices == labels)\n",
    "#             print(\"Vali {0} th batch, {1} correct, validated {2}, batch size {3}\".format(i, \n",
    "#                                                                           predicted_correct_num,\n",
    "#                                                                           batch_size*(i+1), batch_size))\n",
    "\n",
    "        accu_vali = predicted_correct_num.item() / total_vali\n",
    "        accu_vali_list.append(accu_vali)\n",
    "        \n",
    "        print(\"Training Accu: \", accu_train)\n",
    "        print(\"Validation Accu: \", accu_vali)\n",
    "\n",
    "    print('Finish Traning')\n",
    "    \n",
    "    # test current model with highest vali accu\n",
    "    test_accu = test_model(model, testloader)\n",
    "    \n",
    "    # plot accu with epoch\n",
    "    plt.plot(range(epochs), accu_train_list, label=\"Train\")\n",
    "    plt.plot(range(epochs), accu_vali_list, label=\"Vali\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    return model, accu_vali, test_accu\n",
    "\n",
    "def avg_d_dimensional_list(lst):\n",
    "    avg_list = []\n",
    "    for l in lst:\n",
    "        avg_list.append(mean(l))\n",
    "    return avg_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A5a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# A5a\n",
    "# train logistic regression\n",
    "batch_size = 1000\n",
    "\n",
    "# load data\n",
    "trainset, trainloader, testset, testloader = load_data(batch_size = batch_size)\n",
    "\n",
    "# define model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# define a loss function\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "lr_list = [0.001, 0.002, 0.003, 0.004, 0.005]\n",
    "lr_accu_list = [[] for i in range(len(lr_list))]\n",
    "momentum_list = [0.2, 0.4, 0.6, 0.8, 0.9]\n",
    "momentum_accu_list = [[] for i in range(len(momentum_list))]\n",
    "\n",
    "vali_acct_best = 0\n",
    "test_accu_best = 0\n",
    "\n",
    "for lr in lr_list:\n",
    "    for momentum in momentum_list:\n",
    "        print(\"lr: \", lr, \", momen: \", momentum)\n",
    "        # define optimizer\n",
    "        optimizer = torch.optim.SGD(model.parameters(), \n",
    "                                    lr=lr, \n",
    "                                    momentum=momentum)\n",
    "\n",
    "        model, accu_vali, test_accu = train_and_vali(trainset=trainset, \n",
    "                                                     model=model, \n",
    "                                                     optimizer=optimizer, \n",
    "                                                     testloader=testloader,\n",
    "                                                     epochs=30, \n",
    "                                                     batch_print_num=20, \n",
    "                                                     batch_size=batch_size, \n",
    "                                                     title=\"Logistic Regression\") \n",
    "        lr_accu_list[lr_list.index(lr)].append(accu_vali)\n",
    "        momentum_accu_list[momentum_list.index(momentum)].append(accu_vali)\n",
    "        \n",
    "        if accu_vali > vali_acct_best:\n",
    "            vali_acct_best = accu_vali\n",
    "            test_accu_best = test_accu\n",
    "            best_params = {\"lr\":lr,\"momentum\": momentum}\n",
    "        print(\"Vali Accu: \", accu_vali, \"Best vali: \", vali_acct_best, \n",
    "              \"Test Accu: \", test_accu, \"Best params: \", best_params)\n",
    "\n",
    "print(\"Best vali accu: {0}, Best test accu: {1}, Best param set: {2}\".format(accu_vali, \n",
    "                                                                             test_accu, \n",
    "                                                                             best_params))\n",
    "lr_accu_avg_list = avg_d_dimensional_list(lr_accu_list)\n",
    "momentum_avg_list = avg_d_dimensional_list(momentum_accu_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot lr and momentum change with accu plots\n",
    "plt.plot(lr_list, lr_accu_avg_list)\n",
    "plt.xlabel(\"Learning Rate\")\n",
    "plt.ylabel(\"Validation Accu\")\n",
    "plt.title(\"Lr vs Vali Accu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot momentum change with accu plotsu\n",
    "plt.plot(momentum_list, momentum_avg_list)\n",
    "plt.xlabel(\"Momentum\")\n",
    "plt.ylabel(\"Validation Accu\")\n",
    "plt.title(\"Momen vs Vali_Accu\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A5b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 29 µs, sys: 11 µs, total: 40 µs\n",
      "Wall time: 55.8 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# A5b\n",
    "# define model one linear hidden layer\n",
    "class OneHiddenLayer(torch.nn.Module):\n",
    "    def __init__(self, M):\n",
    "        super(OneHiddenLayer, self).__init__()\n",
    "        self.linear = torch.nn.Linear(3072, M)\n",
    "        self.linear2 = torch.nn.Linear(M, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.sigmoid(self.linear(x))\n",
    "        x = self.linear2(x)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# A5b\n",
    "# train one linear hidden layer\n",
    "batch_size = 1000\n",
    "\n",
    "# load data\n",
    "trainset, trainloader, testset, testloader = load_data(batch_size = batch_size)\n",
    "\n",
    "# define a loss function\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "lr_list = [0.001, 0.003, 0.005]\n",
    "lr_accu_list = [[] for i in range(len(lr_list))]\n",
    "momentum_list = [0.3, 0.6, 0.9]\n",
    "momentum_accu_list = [[] for i in range(len(momentum_list))]\n",
    "M_list = [50, 150, 300]\n",
    "M_accu_list = [[] for i in range(len(M_list))]\n",
    "\n",
    "vali_acct_best = 0\n",
    "test_accu_best = 0\n",
    "\n",
    "for lr in lr_list:\n",
    "    for momentum in momentum_list:\n",
    "        for M in M_list:\n",
    "            print(\"lr: \", lr, \", momen: \", momentum, \"M: \", M)\n",
    "            # define model\n",
    "            model = OneHiddenLayer(M)\n",
    "            # define optimizer\n",
    "            optimizer = torch.optim.SGD(model.parameters(), \n",
    "                                        lr=lr, \n",
    "                                        momentum=momentum)\n",
    "\n",
    "            model, accu_vali, test_accu = train_and_vali(trainset=trainset, \n",
    "                                                         model=model, \n",
    "                                                         optimizer=optimizer, \n",
    "                                                         testloader=testloader,\n",
    "                                                         epochs=30, \n",
    "                                                         batch_print_num=20, \n",
    "                                                         batch_size=batch_size, \n",
    "                                                         title=\"One Hiddent Layer Model\") \n",
    "            lr_accu_list[lr_list.index(lr)].append(accu_vali)\n",
    "            momentum_accu_list[momentum_list.index(momentum)].append(accu_vali)\n",
    "            M_accu_list[M_list.index(M)].append(accu_vali)\n",
    "\n",
    "            if accu_vali > vali_acct_best:\n",
    "                vali_acct_best = accu_vali\n",
    "                test_accu_best = test_accu\n",
    "                best_params = {\"lr\": lr,\"momentum\": momentum, \"M\": M}\n",
    "            print(\"Vali Accu: \", accu_vali, \"Best vali: \", vali_acct_best, \n",
    "                  \"Test Accu: \", test_accu, \"Best params: \", best_params)\n",
    "\n",
    "print(\"Best vali accu: {0}, Best test accu: {1}, Best param set: {2}\".format(accu_vali, \n",
    "                                                                             test_accu, \n",
    "                                                                             best_params))\n",
    "lr_accu_avg_list = avg_d_dimensional_list(lr_accu_list)\n",
    "momentum_avg_list = avg_d_dimensional_list(momentum_accu_list)\n",
    "M_avg_list = avg_d_dimensional_list(M_accu_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A5c\n",
    "-  **torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros')**\n",
    "- in_channels (int) – Number of channels in the input image\n",
    "- out_channels (int) – Number of channels produced by the convolution\n",
    "- kernel_size (int or tuple) – Size of the convolving kernel\n",
    "- stride (int or tuple, optional) – Stride of the convolution. (Default: 1)\n",
    "- padding (int or tuple, optional) – Zero-padding added to both sides of the input (Default: 0)\n",
    "- padding_mode (string, optional) – zeros\n",
    "- dilation (int or tuple, optional) – Spacing between kernel elements. (Default: 1)\n",
    "- groups (int, optional) – Number of blocked connections from input to output channels. (Default: 1)\n",
    "- bias (bool, optional) – If True, adds a learnable bias to the output. (Default: True)\n",
    "- Visualize https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 40 µs, sys: 222 µs, total: 262 µs\n",
      "Wall time: 675 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Convolutional layer with max-pool and fully-connected output\n",
    "class CNN(torch.nn.Module):\n",
    "    def __init__(self, M,k,N):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=M, kernel_size=k)\n",
    "        self.linear1 = torch.nn.Linear(M*(int((33-k)/N))**2, 10)\n",
    "        self.N = N\n",
    "        self.M = M\n",
    "        self.k = k\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, (self.N, self.N))\n",
    "        x = x.view(1000, -1)\n",
    "#         print(M*(int((33-k)/N))**2, x.size())\n",
    "        x = self.linear1(x)\n",
    "        return x "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A5d Fine tune Previous Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "lr:  0.001 , momen:  0.3 M:  50 k:  5 N:  4\n",
      "torch.Size([1000, 3, 32, 32])\n",
      "2450 torch.Size([1000, 2450])\n",
      "torch.Size([1000, 3, 32, 32])\n",
      "2450 torch.Size([1000, 2450])\n",
      "torch.Size([1000, 3, 32, 32])\n",
      "2450 torch.Size([1000, 2450])\n",
      "torch.Size([1000, 3, 32, 32])\n",
      "2450 torch.Size([1000, 2450])\n",
      "torch.Size([1000, 3, 32, 32])\n",
      "2450 torch.Size([1000, 2450])\n",
      "torch.Size([1000, 3, 32, 32])\n",
      "2450 torch.Size([1000, 2450])\n",
      "torch.Size([1000, 3, 32, 32])\n",
      "2450 torch.Size([1000, 2450])\n",
      "torch.Size([1000, 3, 32, 32])\n",
      "2450 torch.Size([1000, 2450])\n",
      "torch.Size([1000, 3, 32, 32])\n",
      "2450 torch.Size([1000, 2450])\n",
      "torch.Size([1000, 3, 32, 32])\n",
      "2450 torch.Size([1000, 2450])\n",
      "torch.Size([1000, 3, 32, 32])\n",
      "2450 torch.Size([1000, 2450])\n",
      "torch.Size([1000, 3, 32, 32])\n",
      "2450 torch.Size([1000, 2450])\n",
      "torch.Size([1000, 3, 32, 32])\n",
      "2450 torch.Size([1000, 2450])\n",
      "torch.Size([1000, 3, 32, 32])\n",
      "2450 torch.Size([1000, 2450])\n",
      "torch.Size([1000, 3, 32, 32])\n",
      "2450 torch.Size([1000, 2450])\n",
      "torch.Size([1000, 3, 32, 32])\n",
      "2450 torch.Size([1000, 2450])\n",
      "torch.Size([1000, 3, 32, 32])\n",
      "2450 torch.Size([1000, 2450])\n",
      "torch.Size([1000, 3, 32, 32])\n",
      "2450 torch.Size([1000, 2450])\n",
      "torch.Size([1000, 3, 32, 32])\n",
      "2450 torch.Size([1000, 2450])\n",
      "torch.Size([1000, 3, 32, 32])\n",
      "2450 torch.Size([1000, 2450])\n",
      "[1, 20000] loss: 2.301\n",
      "torch.Size([1000, 3, 32, 32])\n",
      "2450 torch.Size([1000, 2450])\n",
      "torch.Size([1000, 3, 32, 32])\n",
      "2450 torch.Size([1000, 2450])\n",
      "torch.Size([1000, 3, 32, 32])\n",
      "2450 torch.Size([1000, 2450])\n",
      "torch.Size([1000, 3, 32, 32])\n",
      "2450 torch.Size([1000, 2450])\n",
      "torch.Size([1000, 3, 32, 32])\n",
      "2450 torch.Size([1000, 2450])\n",
      "torch.Size([1000, 3, 32, 32])\n",
      "2450 torch.Size([1000, 2450])\n",
      "torch.Size([1000, 3, 32, 32])\n",
      "2450 torch.Size([1000, 2450])\n",
      "torch.Size([1000, 3, 32, 32])\n",
      "2450 torch.Size([1000, 2450])\n",
      "torch.Size([1000, 3, 32, 32])\n",
      "2450 torch.Size([1000, 2450])\n",
      "torch.Size([1000, 3, 32, 32])\n",
      "2450 torch.Size([1000, 2450])\n",
      "torch.Size([1000, 3, 32, 32])\n",
      "2450 torch.Size([1000, 2450])\n",
      "torch.Size([1000, 3, 32, 32])\n",
      "2450 torch.Size([1000, 2450])\n",
      "torch.Size([1000, 3, 32, 32])\n",
      "2450 torch.Size([1000, 2450])\n",
      "torch.Size([1000, 3, 32, 32])\n",
      "2450 torch.Size([1000, 2450])\n",
      "torch.Size([1000, 3, 32, 32])\n",
      "2450 torch.Size([1000, 2450])\n",
      "torch.Size([1000, 3, 32, 32])\n",
      "2450 torch.Size([1000, 2450])\n",
      "torch.Size([1000, 3, 32, 32])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36mtrain_and_vali\u001b[0;34m(trainset, model, optimizer, title, testloader, epochs, batch_print_num, batch_size)\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mrelu\u001b[0;34m(input, inplace)\u001b[0m\n\u001b[1;32m   1061\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1064\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# A5c\n",
    "# Convolutional layer with max-pool and fully-connected output\n",
    "batch_size = 1000\n",
    "\n",
    "# load data\n",
    "trainset, trainloader, testset, testloader = load_data(batch_size = batch_size)\n",
    "\n",
    "# define a loss function\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "lr_list = [0.001, 0.003, 0.005]\n",
    "lr_accu_list = [[] for i in range(len(lr_list))]\n",
    "momentum_list = [0.3, 0.6, 0.9]\n",
    "momentum_accu_list = [[] for i in range(len(momentum_list))]\n",
    "M_list = [50, 100, 150]\n",
    "M_accu_list = [[] for i in range(len(M_list))]\n",
    "k_list = [5]\n",
    "k_accu_list = [[] for i in range(len(k_list))]\n",
    "N_list = [4, 7, 14]\n",
    "N_accu_list = [[] for i in range(len(N_list))]\n",
    "\n",
    "vali_acct_best = 0\n",
    "test_accu_best = 0\n",
    "\n",
    "# Hyperparameters\n",
    "# lr: Learning Rate\n",
    "# momentum\n",
    "# M: conv2d Filter size\n",
    "# k: conv2d kernel size\n",
    "# N: Maxpool kernel size, it is square in this case\n",
    "for lr in lr_list:\n",
    "    for momentum in momentum_list:\n",
    "        for M in M_list:\n",
    "            for k in k_list:\n",
    "                for N in N_list:\n",
    "                    \n",
    "                    print(\"lr: \", lr, \", momen: \", momentum, \n",
    "                          \"M: \", M,\"k: \", k, \"N: \", N )\n",
    "                    # define model\n",
    "                    model = CNN(M, k, N)\n",
    "                    # define optimizer\n",
    "                    optimizer = torch.optim.SGD(model.parameters(), \n",
    "                                                lr=lr, \n",
    "                                                momentum=momentum)\n",
    "\n",
    "                    model, accu_vali, test_accu = train_and_vali(trainset=trainset, \n",
    "                                                                 model=model, \n",
    "                                                                 optimizer=optimizer, \n",
    "                                                                 testloader=testloader,\n",
    "                                                                 epochs=30, \n",
    "                                                                 batch_print_num=20, \n",
    "                                                                 batch_size=batch_size, \n",
    "                                                                 title=\"Conv-Maxpool-linear-CNN\") \n",
    "                    lr_accu_list[lr_list.index(lr)].append(accu_vali)\n",
    "                    momentum_accu_list[momentum_list.index(momentum)].append(accu_vali)\n",
    "                    M_accu_list[M_list.index(M)].append(accu_vali)\n",
    "                    k_accu_list[k_list.index(k)].append(accu_vali)\n",
    "                    N_accu_list[N_list.index(N)].append(accu_vali)\n",
    "\n",
    "                    if accu_vali > vali_acct_best:\n",
    "                        vali_acct_best = accu_vali\n",
    "                        test_accu_best = test_accu\n",
    "                        best_params = {\"lr\": lr,\"momentum\": momentum, \n",
    "                                       \"M\": M, \"k\":k, \"N\":N}\n",
    "                    print(\"Vali Accu: \", accu_vali, \"Best vali: \", vali_acct_best, \n",
    "                          \"Test Accu: \", test_accu, \"Best params: \", best_params)\n",
    "\n",
    "print(\"Best vali accu: {0}, Best test accu: {1}, Best param set: {2}\".format(accu_vali, \n",
    "                                                                             test_accu, \n",
    "                                                                             best_params))\n",
    "lr_accu_avg_list = avg_d_dimensional_list(lr_accu_list)\n",
    "momentum_avg_list = avg_d_dimensional_list(momentum_accu_list)\n",
    "M_avg_list = avg_d_dimensional_list(M_accu_list)\n",
    "k_avg_list = avg_d_dimensional_list(k_accu_list)\n",
    "N_avg_list = avg_d_dimensional_list(N_accu_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot lr change with accu plots\n",
    "plt.plot(lr_list, lr_accu_avg_list)\n",
    "plt.xlabel(\"Learning Rate\")\n",
    "plt.ylabel(\"Validation Accu\")\n",
    "plt.title(\"Lr vs Vali Accu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot momentum change with accu plotsu\n",
    "plt.plot(momentum_list, momentum_avg_list)\n",
    "plt.xlabel(\"Momentum\")\n",
    "plt.ylabel(\"Validation Accu\")\n",
    "plt.title(\"Momen vs Vali_Accu\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot M\n",
    "plt.plot(M_list, M_avg_list)\n",
    "plt.xlabel(\"M-Filter Size\")\n",
    "plt.ylabel(\"Validation Accu\")\n",
    "plt.title(\"M vs Vali_Accu\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot k\n",
    "plt.plot(k_list, k_avg_list)\n",
    "plt.xlabel(\"k-Conv-Kernel Size\")\n",
    "plt.ylabel(\"Validation Accu\")\n",
    "plt.title(\"k vs Vali_Accu\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot N\n",
    "plt.plot(N_list, N_avg_list)\n",
    "plt.xlabel(\"N-Maxpool Size\")\n",
    "plt.ylabel(\"Validation Accu\")\n",
    "plt.title(\"N vs Vali_Accu\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
